{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "432ff493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "regex = re.compile('[^a-z ]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "9ab9e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitizeBasic(sent):\n",
    "    #remove all punctuations and numbers\n",
    "    sent=regex.sub(' ', sent)\n",
    "    sent=re.sub(r\"[ ]+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "93d80374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitizeStem(sent):\n",
    "    #remove all punctuations, numbers and stem as well\n",
    "    sent=regex.sub(' ', sent)\n",
    "    sent=re.sub(r\"[ ]+\", \" \", sent)\n",
    "    sent= porter.stem(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "b5c25444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitizeStemStopWords(sent):\n",
    "    #remove all punctuations, numbers and stop words. Do stemming \n",
    "    sent=regex.sub(' ', sent)\n",
    "    sent=re.sub(r\"[ ]+\", \" \", sent)\n",
    "    sent=sent.split(\" \")\n",
    "    sent=' '.join([w for w in sent if w not in stop_words])\n",
    "    sent= porter.stem(sent)\n",
    "    \n",
    "#     sent = re.sub(r\"[\\*\\\"“”\\n\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;\\.\\,\\&\\?]+\", \" \", sent)\n",
    "#     sent = re.sub(r\"[0-9]+\", \"\", sent)\n",
    "#     sent = re.sub(r\"[\\']+\", \"\", sent)\n",
    "#     sent=re.sub(r\"[ ]+\", \" \", sent)\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "484b3c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitize=sanitizeStemStopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "009c14b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard believe memory trees came years ago held well passage time enya last great album new age pop amarantine day without rain back enya still creative spark voice agree reviewer said saddest album melancholy bittersweet opening title song memory trees elegaic majestic pax deorum sounds like requiem mass dark threnody unlike reviewer said disconcerting blend spirituality sensuality find disconcerting anywhere hopeful song looking possibilities hope place love listener decide romantic platonic etc always soft spot song way home triumphant ending return truly masterpiece new age music must enya fan \n"
     ]
    }
   ],
   "source": [
    "print(sanitize(\"It's hard to believe \\\"Memory of Trees\\\" came out 11 years ago;it has held up well over the passage of time.It's Enya's last great album before the New Age/pop of \\\"Amarantine\\\" and \\\"Day without rain.\\\" Back in 1995,Enya still had her creative spark,her own voice.I agree with the reviewer who said that this is her saddest album;it is melancholy,bittersweet,from the opening title song.\\\"Memory of Trees\\\" is elegaic&majestic.;\\\"Pax Deorum\\\" sounds like it is from a Requiem Mass,it is a dark threnody.Unlike the reviewer who said that this has a \\\"disconcerting\\\" blend of spirituality&sensuality;,I don't find it disconcerting at all.\\\"Anywhere is\\\" is a hopeful song,looking to possibilities.\\\"Hope has a place\\\" is about love,but it is up to the listener to decide if it is romantic,platonic,etc.I've always had a soft spot for this song.\\\"On my way home\\\" is a triumphant ending about return.This is truly a masterpiece of New Age music,a must for any Enya fan!\".lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "13676140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play\n"
     ]
    }
   ],
   "source": [
    "print(sanitize('playing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f21d3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "a40ceb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_json('Music_reviews_json/reviews_Digital_Music_5.json/Music_Review_train.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "a23a4a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contains the text data\n",
    "dat=data[['reviewText']].copy()\n",
    "# print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "1ed45b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contains the class data \n",
    "df_overall=data[['overall']].astype(int).copy()\n",
    "# print(df_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "45f8a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the frequencies of words in a sentence and returns a dictionary\n",
    "def findFreq(sent):\n",
    "    val=sent.split(\" \")\n",
    "    freq={}\n",
    "    for s in val:\n",
    "        if s not in freq:\n",
    "            freq[s]=1\n",
    "        else:\n",
    "            freq[s]+=1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "29c1b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['reviewText']=dat['reviewText'].str.lower()\n",
    "# print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "acbd98f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['reviewText']=dat['reviewText'].apply(sanitize)\n",
    "# print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "42c950f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the length of each sentence in data\n",
    "example_length=pd.DataFrame()\n",
    "example_length['length']=dat['reviewText'].apply(len)\n",
    "# print(example_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b40f5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dat.iloc[432]['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "164342e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df=pd.DataFrame()\n",
    "freq_df['reviewText']=dat['reviewText'].apply(findFreq)\n",
    "# print(freq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "08fc638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=set()\n",
    "num_examples=df_overall.shape[0]\n",
    "for d in range(num_examples):\n",
    "    for k in freq_df.iloc[d]['reviewText'].keys():\n",
    "        if k not in vocab:\n",
    "            vocab.add(k)\n",
    "# print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "c707de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "e0eb42d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "28dd75f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_denom={} #the summation of length of reviews depending upon their class\n",
    "num_classes=5\n",
    "for i in range(1,num_classes+1):\n",
    "    sum_denom[i]=0\n",
    "for i in range(num_examples):\n",
    "    k=df_overall.iloc[i]['overall']\n",
    "    sum_denom[k]+=example_length.iloc[i]['length']\n",
    "# print(sum_denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "8e2309bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_numer={} #the sum of the numerator for each theta\n",
    "for word in vocab:\n",
    "    sum_numer[word]={}\n",
    "    for i in range(1,num_classes+1):\n",
    "        sum_numer[word][i]=0\n",
    "for i in range(num_examples):\n",
    "    k=df_overall.iloc[i]['overall']\n",
    "    d=freq_df.iloc[i]['reviewText']\n",
    "    for j in d:\n",
    "        sum_numer[j][k]+=d[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "fc873dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "thetas={}\n",
    "for word in vocab:\n",
    "    thetas[word]={}\n",
    "    for i in range(1,num_classes+1):\n",
    "        thetas[word][i]=math.log((sum_numer[word][i]+1)/(sum_denom[i]+vocab_size+1)) # +1 in denominator for unk token(words not in vobabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "ef79cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(thetas['have'])\n",
    "# print(thetas['counterparts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "6f2bbe0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          size\n",
      "overall       \n",
      "1         2529\n",
      "2         2638\n",
      "3         5634\n",
      "4        13267\n",
      "5        25932\n"
     ]
    }
   ],
   "source": [
    "#calculate p(y=k)\n",
    "df_overall_size=df_overall.groupby('overall')\n",
    "df_overall_size=df_overall_size['overall'].agg(['size'])\n",
    "df_overall_size['size']=df_overall_size['size']/num_examples\n",
    "df_overall_size['size']=df_overall_size['size'].apply(math.log)\n",
    "# print(df['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "531e06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unk tokens\n",
    "unk_p={i:math.log(1/(sum_denom[i]+vocab_size+1)) for i in range(1,num_classes+1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "de7bf2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training done. testing\n",
    "test=pd.read_json('Music_reviews_json/reviews_Digital_Music_5.json/Music_Review_test.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "a6b3a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testR=pd.DataFrame()\n",
    "testR['reviewText']=test['reviewText'].copy().str.lower().apply(sanitize)\n",
    "testO=pd.DataFrame()\n",
    "testO['overall']=test['overall'].astype(int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "700f4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueWords(sent):\n",
    "    arr=sent.split(\" \")\n",
    "    s=set()\n",
    "    for a in arr:\n",
    "        if a not in s:\n",
    "            s.add(a)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "015e98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testR['reviewText']=testR['reviewText'].apply(uniqueWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "565f1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(testR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "3272a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictV(setS):\n",
    "    d={i:df_overall_size['size'][i] for i in range(1, num_classes+1)}\n",
    "    for s in setS:\n",
    "        if s not in thetas:\n",
    "            for i in range(1, num_classes+1):\n",
    "                d[i]+=unk_p[i]\n",
    "        else:\n",
    "            for i in range(1, num_classes+1):\n",
    "                d[i]+=thetas[s][i]\n",
    "    return max(d,key=d.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "a30f1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=pd.DataFrame()\n",
    "predict['val']=testR['reviewText'].apply(predictV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "0d4b2b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       val\n",
      "0        5\n",
      "1        2\n",
      "2        3\n",
      "3        5\n",
      "4        3\n",
      "...    ...\n",
      "13995    5\n",
      "13996    4\n",
      "13997    4\n",
      "13998    4\n",
      "13999    4\n",
      "\n",
      "[14000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "3f0a5283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5249285714285714\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "for i in range(14000):\n",
    "    if predict.iloc[i]['val']==testO.iloc[i]['overall']:\n",
    "        a+=1;\n",
    "print(a/14000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "a8a66f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 130,   46,   17,    9,   26],\n",
       "       [  71,  116,   70,   25,   44],\n",
       "       [  72,  267,  304,  214,  229],\n",
       "       [ 240,  431,  529,  665, 1243],\n",
       "       [1008,  827,  432,  851, 6134]])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(testO, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "879853a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall\n",
      "1     228\n",
      "2     326\n",
      "3    1086\n",
      "4    3108\n",
      "5    9252\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(testO.groupby('overall').agg('size'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
