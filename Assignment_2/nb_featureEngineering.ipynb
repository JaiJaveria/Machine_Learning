{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "432ff493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "regex = re.compile('[^a-z ]')\n",
    "regexN = re.compile('[^a-z0-9 ]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "9ab9e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitizeBasic(sent):\n",
    "    #remove all punctuations and numbers\n",
    "    sent=regexN.sub(' ', sent)\n",
    "    sent=re.sub(r\"[ ]+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "93d80374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitizeStem(sent):\n",
    "    #remove all punctuations, numbers and stem as well\n",
    "    sent=regexN.sub(' ', sent)\n",
    "    sent=re.sub(r\"[ ]+\", \" \", sent)\n",
    "    sent= porter.stem(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b5c25444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitizeStemStopWords(sent):\n",
    "    #remove all punctuations, numbers and stop words. Do stemming \n",
    "    sent=regexN.sub(' ', sent)\n",
    "    sent=re.sub(r\"[ ]+\", \" \", sent)\n",
    "    sent=sent.split(\" \")\n",
    "    sent=' '.join([w for w in sent if w not in stop_words])\n",
    "    sent= porter.stem(sent)\n",
    "    \n",
    "#     sent = re.sub(r\"[\\*\\\"“”\\n\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;\\.\\,\\&\\?]+\", \" \", sent)\n",
    "#     sent = re.sub(r\"[0-9]+\", \"\", sent)\n",
    "#     sent = re.sub(r\"[\\']+\", \"\", sent)\n",
    "#     sent=re.sub(r\"[ ]+\", \" \", sent)\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "484b3c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitize=sanitizeStemStopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "f21d3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a40ceb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_json('Music_reviews_json/reviews_Digital_Music_5.json/Music_Review_train.json', lines=True)\n",
    "data=data[['reviewText','overall']]\n",
    "#contains the class data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6b177138",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1ed45b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contains the class data \n",
    "df_overall=data[['overall']].astype(int).copy()\n",
    "# print(df_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "45f8a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the frequencies of words in a sentence and returns a dictionary\n",
    "def findFreq(sent):\n",
    "    val=sent.split(\" \")\n",
    "    freq={}\n",
    "    for s in val:\n",
    "        if s not in freq:\n",
    "            freq[s]=1\n",
    "        else:\n",
    "            freq[s]+=1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "29c1b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviewText']=data['reviewText'].str.lower()\n",
    "# print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "acbd98f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviewText']=data['reviewText'].apply(sanitize)\n",
    "# print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "95d12cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "lessImpWords=json.load(open('lessImpWords2.json'))\n",
    "for i in range(1, num_classes+1):\n",
    "    lessImpWords[i]=set(lessImpWords.pop(str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f4af7bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueWords(arr):\n",
    "    s=set()\n",
    "    for a in arr:\n",
    "        if a not in s:\n",
    "            s.add(a)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "efa949df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLessImpWords(sent, o):\n",
    "# def removeLessImpWords(sent ):\n",
    "    orig=sent.split(' ')\n",
    "    arr=uniqueWords(orig)\n",
    "    lessImp=[w for w in arr if w in lessImpWords[o]]\n",
    "    sent= ' '.join([w for w in orig if w not in lessImp ])\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "665aebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(lessImpWords.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "239c2eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviewText']=data.apply(lambda x: removeLessImpWords(x.reviewText,x.overall) , axis=1)\n",
    "# data['reviewText']=data.apply(lambda x: removeLessImpWords(x.reviewText, x.overall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d821ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contains the text data\n",
    "dat=data[['reviewText']].copy()\n",
    "# print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "42c950f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the length of each sentence in data\n",
    "example_length=pd.DataFrame()\n",
    "example_length['length']=dat['reviewText'].apply(len)\n",
    "# print(example_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "b40f5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dat.iloc[432]['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "164342e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df=pd.DataFrame()\n",
    "freq_df['reviewText']=dat['reviewText'].apply(findFreq)\n",
    "# print(freq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "08fc638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=set()\n",
    "num_examples=df_overall.shape[0]\n",
    "for d in range(num_examples):\n",
    "    for k in freq_df.iloc[d]['reviewText'].keys():\n",
    "        if k not in vocab:\n",
    "            vocab.add(k)\n",
    "# print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c707de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "e0eb42d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "28dd75f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_denom={} #the summation of length of reviews depending upon their class\n",
    "\n",
    "for i in range(1,num_classes+1):\n",
    "    sum_denom[i]=0\n",
    "for i in range(num_examples):\n",
    "    k=df_overall.iloc[i]['overall']\n",
    "    sum_denom[k]+=example_length.iloc[i]['length']\n",
    "# print(sum_denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "8e2309bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_numer={} #the sum of the numerator for each theta\n",
    "for word in vocab:\n",
    "    sum_numer[word]={}\n",
    "    for i in range(1,num_classes+1):\n",
    "        sum_numer[word][i]=0\n",
    "for i in range(num_examples):\n",
    "    k=df_overall.iloc[i]['overall']\n",
    "    d=freq_df.iloc[i]['reviewText']\n",
    "    for j in d:\n",
    "        sum_numer[j][k]+=d[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "fc873dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "thetas={}\n",
    "for word in vocab:\n",
    "    thetas[word]={}\n",
    "    for i in range(1,num_classes+1):\n",
    "        thetas[word][i]=math.log((sum_numer[word][i]+1)/(sum_denom[i]+vocab_size+1)) # +1 in denominator for unk token(words not in vobabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "ef79cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(thetas['have'])\n",
    "# print(thetas['counterparts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "6f2bbe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate p(y=k)\n",
    "df_overall_size=df_overall.groupby('overall')\n",
    "df_overall_size=df_overall_size['overall'].agg(['size'])\n",
    "df_overall_size['size']=df_overall_size['size']/num_examples\n",
    "df_overall_size['size']=df_overall_size['size'].apply(math.log)\n",
    "# print(df['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "531e06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unk tokens\n",
    "unk_p={i:math.log(1/(sum_denom[i]+vocab_size+1)) for i in range(1,num_classes+1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "de7bf2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training done. testing\n",
    "test=pd.read_json('Music_reviews_json/reviews_Digital_Music_5.json/Music_Review_test.json', lines=True)\n",
    "test['reviewText']=test['reviewText'].copy().str.lower().apply(sanitize)\n",
    "test['reviewText']=test.apply(lambda x: removeLessImpWords(x.reviewText,x.overall) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a6b3a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testR=pd.DataFrame()\n",
    "testR['reviewText']=test['reviewText'].str.split(' ')\n",
    "testO=pd.DataFrame()\n",
    "testO['overall']=test['overall'].astype(int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700f4281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "015e98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testR['reviewText']=testR['reviewText'].apply(uniqueWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "565f1186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              reviewText\n",
      "0      [hard, believe, memory, trees, came, 11, years...\n",
      "1      [clasically, styled, introverted, album, memor...\n",
      "2      [never, thought, enya, would, reach, sublime, ...\n",
      "3      [third, review, irish, album, write, today, ot...\n",
      "4      [enya, despite, successful, recording, artist,...\n",
      "...                                                  ...\n",
      "13995  [grew, rush, since, 1987, good, album, never, ...\n",
      "13996  [positive, side, nearly, every, song, cd, leas...\n",
      "13997  [rush, never, band, stagnate, constantly, expl...\n",
      "13998  [glassy, relatively, pop, oriented, sound, quo...\n",
      "13999  [album, elements, old, style, along, elements,...\n",
      "\n",
      "[14000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(testR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "3272a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictV(setS):\n",
    "    d={i:df_overall_size['size'][i] for i in range(1, num_classes+1)}\n",
    "    for s in setS:\n",
    "        if s not in thetas:\n",
    "            for i in range(1, num_classes+1):\n",
    "                d[i]+=unk_p[i]\n",
    "        else:\n",
    "            for i in range(1, num_classes+1):\n",
    "                d[i]+=thetas[s][i]\n",
    "    return max(d,key=d.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0e8cdbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "a30f1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=pd.DataFrame()\n",
    "predict['val']=testR['reviewText'].apply(predictV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "bb800a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dat)\n",
    "predictTrain=pd.DataFrame()\n",
    "predictTrain['val']=(dat['reviewText'].str.split(' ')).apply(predictV)\n",
    "# predictTrain['val']=dat['reviewText'].apply(uniqueWords).apply(predictV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "e8e4baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predictTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "0d4b2b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 0.5822\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "for i in range(50000):\n",
    "    if predictTrain.iloc[i]['val']==df_overall.iloc[i]['overall']:\n",
    "        a+=1;\n",
    "print(\"Training Accuracy\", a/50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "3f0a5283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy 0.5125714285714286\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "for i in range(14000):\n",
    "    if predict.iloc[i]['val']==testO.iloc[i]['overall']:\n",
    "        a+=1;\n",
    "print(\"Testing Accuracy\",a/14000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "a8a66f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 148,   48,    7,    7,   18],\n",
       "       [  70,  174,   35,   18,   29],\n",
       "       [ 110,  305,  337,  156,  178],\n",
       "       [ 355,  530,  445,  720, 1058],\n",
       "       [1379, 1004,  379,  693, 5797]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(testO, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "879853a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall\n",
      "1     228\n",
      "2     326\n",
      "3    1086\n",
      "4    3108\n",
      "5    9252\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(testO.groupby('overall').agg('size'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
